import streamlit as st
import os
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent))
from training.train_model import train_model

def main():
    st.set_page_config(
        page_title="syslog-packet analyzer",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    st.title("syslog-packet analyzer")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("í•™ìŠµ ì„¤ì •")
        
        # ë°ì´í„°ì…‹ ê²½ë¡œ ì„ íƒ
        dataset_path = st.text_input(
            "ë°ì´í„°ì…‹ ê²½ë¡œ",
            value="datasets",
            help="í•™ìŠµí•  ë°ì´í„°ì…‹ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ"
        )
        
        # ëª¨ë¸ ì„ íƒ
        model_name = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            options=["meta-llama/Llama-3.2-3B-Instruct", "openai-community/gpt2-medium", "deepseek-ai/DeepSeek-V3"],
            help="í•™ìŠµí•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        output_dir = st.text_input(
            "ì¶œë ¥ ë””ë ‰í† ë¦¬",
            value="output",
            help="í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬"
        )
        
        # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
        st.subheader("í•™ìŠµ íŒŒë¼ë¯¸í„°")
        col1, col2 = st.columns(2)
        
        with col1:
            batch_size = st.number_input(
                "batch size",
                min_value=1,
                max_value=32,
                value=4,
                step=1
            )
            
            epochs = st.number_input(
                "epoch count",
                min_value=1,
                max_value=100,
                value=3,
                step=1
            )
            
            learning_rate = st.number_input(
                "learning rate",
                min_value=1e-6,
                max_value=1e-2,
                value=2e-5,
                format="%.6f"
            )
            
        with col2:
            max_grad_norm = st.number_input(
                "max gradient norm",
                min_value=0.1,
                max_value=10.0,
                value=1.0,
                step=0.1
            )
            
            warmup_ratio = st.number_input(
                "warmup ratio",
                min_value=0.0,
                max_value=0.5,
                value=0.1,
                step=0.01
            )
            
            gradient_accumulation_steps = st.number_input(
                "gradient accumulation step",
                min_value=1,
                max_value=16,
                value=4,
                step=1
            )
        
        # ê³ ê¸‰ ì„¤ì •
        st.subheader("ê³ ê¸‰ ì„¤ì •")
        col3, col4 = st.columns(2)
        
        with col3:
            fp16 = st.checkbox("FP16 í•™ìŠµ", value=True)
            group_by_length = st.checkbox("ì‹œí€€ìŠ¤ ê¸¸ì´ë³„ ê·¸ë£¹í™”", value=True)
            load_best_model_at_end = st.checkbox("í•™ìŠµ ì¢…ë£Œ ì‹œ ìµœì  ëª¨ë¸ ë¡œë“œ", value=True)
            
        with col4:
            lr_scheduler_type = st.selectbox(
                "learn scheduler",
                options=["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"],
                index=1
            )
            
            optim = st.selectbox(
                "optimizer",
                options=["adamw_torch", "adamw_hf", "adamw_apex_fused", "adafactor"],
                index=0
            )
    
    # ë©”ì¸ ì½˜í…ì¸ 
    st.header("í•™ìŠµ ì‹œì‘")
    
    if st.button("í•™ìŠµ ì‹œì‘"):
        with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘..."):
            try:
                # í•™ìŠµ ì‹œì‘
                train_model(
                    dataset_path=dataset_path,
                    model_name=model_name,
                    output_dir=output_dir,
                    batch_size=batch_size,
                    epochs=epochs,
                    learning_rate=learning_rate,
                    max_grad_norm=max_grad_norm,
                    warmup_ratio=warmup_ratio,
                    gradient_accumulation_steps=gradient_accumulation_steps,
                    fp16=fp16,
                    group_by_length=group_by_length,
                    load_best_model_at_end=load_best_model_at_end,
                    lr_scheduler_type=lr_scheduler_type,
                    optim=optim
                )
                
                st.success("í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.info(f"í•™ìŠµëœ ëª¨ë¸ì´ {output_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                st.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if __name__ == "__main__":
    main() 